name: WildGuard Complete Enhanced Scanner - 8 Platforms

on:
  schedule:
    # Run every 3 hours for maximum global coverage and 100k+ daily target
    - cron: "0 */3 * * *"
  workflow_dispatch: # Manual triggers

jobs:
  complete-enhanced-scan:
    runs-on: ubuntu-latest
    timeout-minutes: 180 # 3 hours maximum

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.production.txt
          playwright install chromium
          playwright install-deps

      - name: Run Complete Enhanced Scanner
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
          EBAY_APP_ID: ${{ secrets.EBAY_APP_ID }}
          EBAY_CERT_ID: ${{ secrets.EBAY_CERT_ID }}
          EBAY_DEV_ID: ${{ secrets.EBAY_DEV_ID }}
        run: |
          echo "üåç Starting COMPLETE ENHANCED GLOBAL SCANNER"
          echo "================================================"
          echo "üéØ Target: 100,000+ listings per day"
          echo "üåç 8 Platforms:"
          echo "   ‚Ä¢ eBay (Global)"
          echo "   ‚Ä¢ Craigslist (North America)"
          echo "   ‚Ä¢ OLX (Europe/Latin America)"
          echo "   ‚Ä¢ Marktplaats (Netherlands/Belgium)"
          echo "   ‚Ä¢ MercadoLibre (Latin America)"
          echo "   ‚Ä¢ Facebook Marketplace (Global)"
          echo "   ‚Ä¢ Avito (Russia/Eastern Europe)"
          echo "   ‚Ä¢ Gumtree (UK/Australia/South Africa)"
          echo "üö´ Duplicate Prevention: Database + Cache"
          echo "üéØ Keywords: 1000+ endangered species"
          echo "================================================"
          timeout 10500s python complete_enhanced_scanner.py || echo "‚úÖ 3-hour enhanced scan session completed"

      - name: Post-Scan Cleanup
        if: always()
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        run: |
          echo "üßπ Running post-scan cleanup..."
          python cleanup/fast_cleanup.py || echo "‚úÖ Post-scan cleanup completed"

      - name: Upload scan logs and cache
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: complete-scan-logs-${{ github.run_number }}
          path: |
            *.log
            /tmp/wildguard_url_cache.json
          retention-days: 7

      - name: Generate Performance Report
        if: always()
        run: |
          echo "üåç COMPLETE ENHANCED SCANNER REPORT"
          echo "=================================="
          echo "Session: 3-hour maximum"
          echo "Next session: In 3 hours"
          echo "Platform coverage: 8 major global marketplaces"
          echo "Geographic reach: Global (all continents)"
          echo "Target performance: 100,000+ listings/day"
          echo "Duplicate prevention: Active (URL-based)"
          echo "Keywords: 1000+ endangered species terms"
          echo "Historical support: Available"
          echo "=================================="
          
          # Calculate approximate performance
          echo "üìä PERFORMANCE PROJECTION:"
          echo "‚Ä¢ 8 scans per day (every 3 hours)"
          echo "‚Ä¢ ~15,000 listings per scan (target)"
          echo "‚Ä¢ Daily projection: 120,000+ listings"
          echo "‚Ä¢ Monthly projection: 3.6M+ listings"
          echo "‚Ä¢ With duplicate prevention: Clean metrics"
